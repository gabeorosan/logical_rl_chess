{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00874cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "TODO: \n",
    "learn by adding layers of neurons (and translation/rotate functions?)\n",
    "replay backward through games & learn from it\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a66258",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chess\n",
    "import chess.svg\n",
    "import numpy as np\n",
    "from IPython.display import clear_output\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52580bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def serialize(board):\n",
    "    # https://github.com/geohot/twitchchess\n",
    "    '''\n",
    "    in: board\n",
    "    out: [32 x 8] bitmap serialized board\n",
    "    '''\n",
    "    assert board.is_valid()\n",
    "\n",
    "    bstate = np.zeros(64, np.uint8)\n",
    "    for i in range(64):\n",
    "        pp = board.piece_at(i)\n",
    "        if pp is not None:\n",
    "            bstate[i] = {\"P\": 1, \"N\": 2, \"B\": 3, \"R\": 4, \"Q\": 5, \"K\": 6, \\\n",
    "                 \"p\": 9, \"n\":10, \"b\":11, \"r\":12, \"q\":13, \"k\": 14}[pp.symbol()]\n",
    "    if board.has_queenside_castling_rights(chess.WHITE):\n",
    "        assert bstate[0] == 4\n",
    "        bstate[0] = 7\n",
    "    if board.has_kingside_castling_rights(chess.WHITE):\n",
    "        assert bstate[7] == 4\n",
    "        bstate[7] = 7\n",
    "    if board.has_queenside_castling_rights(chess.BLACK):\n",
    "        assert bstate[56] == 8+4\n",
    "        bstate[56] = 8+7\n",
    "    if board.has_kingside_castling_rights(chess.BLACK):\n",
    "        assert bstate[63] == 8+4\n",
    "        bstate[63] = 8+7\n",
    "    if board.ep_square is not None:\n",
    "        assert bstate[board.ep_square] == 0\n",
    "        bstate[board.ep_square] = 8\n",
    "    bstate = bstate.reshape(8,8)\n",
    "\n",
    "    state = np.zeros((4,8,8), np.uint8)\n",
    "    state[0] = (bstate>>3)&1\n",
    "    state[1] = (bstate>>2)&1\n",
    "    state[2] = (bstate>>1)&1\n",
    "    state[3] = (bstate>>0)&1\n",
    "\n",
    "    return state.reshape(-1, 8)\n",
    "\n",
    "def bitlist_to_int(e):\n",
    "    '''\n",
    "    in: [bits]\n",
    "    out: int\n",
    "    '''\n",
    "    score = 0\n",
    "    for b in e:\n",
    "        score = (score << 1) | b\n",
    "    return score\n",
    "\n",
    "def look2moves(board):\n",
    "    '''\n",
    "    in: board\n",
    "    out: {legal_moves:<legal_moves in resulting position>}\n",
    "    '''\n",
    "    ms = [m for m in board.legal_moves]\n",
    "    m_dict = {}\n",
    "    for m in ms:\n",
    "        b = board.copy()\n",
    "        b.push(m)\n",
    "        m_dict[m] = b.legal_moves\n",
    "    return m_dict\n",
    "\n",
    "def compress_evaluations(meval_dict):\n",
    "    '''\n",
    "    in: {moves:[<int evaluations of resulting positions>}\n",
    "    out: {moves: [<int evaluation of worst resulting position]}\n",
    "    '''\n",
    "    meval_compressed_dict = {}\n",
    "    for m, meval in meval_dict.items():\n",
    "        meval_compressed_dict[m] = max(meval, default=0)\n",
    "    return meval_compressed_dict\n",
    "\n",
    "def objective_result(board):\n",
    "    '''\n",
    "    in: board\n",
    "    out: <objective result>\n",
    "        -1 means lost\n",
    "        0 means unknown\n",
    "        1 means draw\n",
    "    '''\n",
    "    outcome = board.outcome(claim_draw=True)\n",
    "    if outcome is not None:\n",
    "        return -1 if outcome.winner else 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db5cb247",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Player:\n",
    "    def __init__(self):\n",
    "        self.neurons = np.random.randint(0, 2, (1, 32, 8))\n",
    "        self.gradients = np.asarray(np.random.randint(0, 2, (self.neurons.shape)))\n",
    "        self.perceptions = {}\n",
    "        self.judgments = {}\n",
    "        self.knowledge = {}\n",
    "    \n",
    "    def learn(self):\n",
    "        '''\n",
    "        compute and apply gradients (difference between knowledge and judgments) with a random mask\n",
    "        '''\n",
    "        for ix, outcome in self.knowledge.items():\n",
    "            results = []\n",
    "            x = serialize(self.perceptions[ix])\n",
    "            dloss_dx = self.judgments[ix] ^ outcome\n",
    "            dloss_dws = np.zeros_like(self.neurons)\n",
    "            for i in range(len(self.neurons)):\n",
    "                dloss_dws[i] = 1 ^ x & dloss_dx\n",
    "                dloss_dx = 1 ^ self.neurons[i] & dloss_dx\n",
    "            self.neurons = self.neurons ^ self.gradients & dloss_dws\n",
    "            self.gradients = np.asarray(np.random.randint(0, 2, (self.neurons.shape)))\n",
    "            \n",
    "    def think(self, s_board):\n",
    "        '''\n",
    "        in, out: 32x8 byte mapping of board\n",
    "        NAND board bytes with neurons, then split and xor the outputs together until you get a single byte result\n",
    "        '''\n",
    "        x = s_board\n",
    "        for neuron_layer in self.neurons:\n",
    "            x = 1^(np.logical_and(x, neuron_layer))\n",
    "        while len(x) > 1:\n",
    "            x1, x2 = np.split(x, 2)\n",
    "            x = x1 ^ x2\n",
    "        return x\n",
    "    \n",
    "    def act(self, board):\n",
    "        '''\n",
    "        input: board\n",
    "        output: (<best move>, <eval>) || result (if game over)\n",
    "        '''\n",
    "        result = objective_result(board)\n",
    "        if not result:\n",
    "            evals = self.evaluate(board, look2moves(board))\n",
    "            compressed_evals = compress_evaluations(evals)\n",
    "            best_move = min(compressed_evals, key=compressed_evals.get)\n",
    "            beval = compressed_evals[best_move]\n",
    "            if board not in self.perceptions.values():\n",
    "                ix = len(self.perceptions)\n",
    "                self.perceptions[ix] = board.copy()\n",
    "            else:\n",
    "                ix = list(self.perceptions.keys())[list(self.perceptions.values()).index(board)]\n",
    "            self.judgments[ix] = beval\n",
    "            board.push(best_move)\n",
    "            return True\n",
    "        if board not in self.perceptions.values():\n",
    "                ix = len(self.perceptions)\n",
    "                self.perceptions[ix] = board\n",
    "        else:\n",
    "            ix = list(self.perceptions.keys())[list(self.perceptions.values()).index(board)]\n",
    "        self.judgments[ix] = self.think(serialize(board))\n",
    "        self.knowledge[ix] = (result>0) * 128\n",
    "        return False\n",
    "    \n",
    "    def value(self, board):\n",
    "        '''\n",
    "        in: board\n",
    "        out: <byte evaluation>\n",
    "        '''\n",
    "        bbytes = self.think(serialize(board))\n",
    "        while len(bbytes)>1:\n",
    "            bbytes.append(bbytes.pop() ^ bbytes.pop())\n",
    "        return bbytes[0]\n",
    "\n",
    "    def value_move(self, board, move):\n",
    "        '''\n",
    "        in: board, move\n",
    "        out: <int evaluation of resulting position>\n",
    "        '''\n",
    "        b = board.copy()\n",
    "        b.push(move)\n",
    "        return bitlist_to_int(self.value(b))\n",
    "    \n",
    "    def evaluate(self, board, m_dict):\n",
    "        '''\n",
    "        in: board, {legal_moves:[<legal moves in resulting position>]}\n",
    "        out: {legal_moves:[<int evaluation of resulting positions>}\n",
    "        '''\n",
    "        meval_dict = {}\n",
    "        for m, lms in m_dict.items():\n",
    "            b = board.copy()\n",
    "            b.push(m)\n",
    "            m1_evals = [self.value_move(b, lm) for lm in list(lms)]\n",
    "            meval_dict[m] = m1_evals\n",
    "        return meval_dict\n",
    "    \n",
    "    def play(self, n_games):\n",
    "        '''\n",
    "        play n games and learn from them (backpropogate)\n",
    "        '''\n",
    "        board = chess.Board()\n",
    "        for i in range(n_games):\n",
    "            while self.act(board):\n",
    "                pass\n",
    "            self.learn()\n",
    "    def play_vs(self):\n",
    "        '''\n",
    "        play against the ai!\n",
    "        yields board position after each move\n",
    "        '''\n",
    "        board = chess.Board()\n",
    "        while p.act(board): \n",
    "            yield chess.svg.board(board, size=300)\n",
    "            user_turn = True\n",
    "            while user_turn:\n",
    "                user_move = input()\n",
    "                try:\n",
    "                    if chess.Move.from_uci(user_move) in board.legal_moves:\n",
    "                        board.push(chess.Move.from_uci(user_move))\n",
    "                        user_turn = False\n",
    "                except: print('input a legal move in the form <square from><square to>\\nex: g1f3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5483025",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = Player()\n",
    "p.play(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "593bb312",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for bd in p.play_vs():\n",
    "    clear_output(wait=True)\n",
    "    display(bd) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
